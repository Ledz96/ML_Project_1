{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "Using two possible distance measures and rangeof k from 1 to 20 ( maybe can check overfitting with decreasing K)\n",
    "try without standardization and try with mi-max (maybe try with Emmanuel's standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils_data_loading import*\n",
    "from one_hot_encoding import*\n",
    "from utils_features_manipulation import*\n",
    "from utils_nans_manipulation import*\n",
    "from KNN import*\n",
    "\n",
    "trainpath = 'Data/train.csv'\n",
    "testpath = 'Data/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing train data and organizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata,header = load_data(trainpath)\n",
    "\n",
    "X_total, Y_total = structure_data(traindata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OHE\n",
    "Before comparing distances it doesn't make sense to keep categorical variabes as integers instead OHE them. From EDA 3 variabes could be split and considered as categorical. PRI_jet_num definitely since there are only 4 unique values. And the centrality look like they could be split into two distributions with the threshold below.\n",
    "\n",
    "DER_lep_eta_cenrality: nans, 0, 1 threshold 0.5 for 0 vs 1\n",
    "DER_met_phi_centrality: threshold above or below 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nans = replace_bad_data_with_nans(X_total, -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned, nans_indices = replace_nans_with_median(X_nans, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dict for indices\n",
    "original_indices = {\n",
    "    'jet' : header.index('PRI_jet_num')-1,\n",
    "    'phi' : header.index('DER_met_phi_centrality')-1,\n",
    "    'eta' : header.index('DER_lep_eta_centrality')-1\n",
    "}\n",
    "\n",
    "cat_indices = {}\n",
    "\n",
    "for name,index in original_indices.items():\n",
    "    if index not in nans_indices:\n",
    "        skip = len([i for i in nans_indices if i < index])\n",
    "        cat_indices[name] = index - skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing OHE for jets\n",
    "jets = X_cleaned[:, cat_indices['jet']].astype(np.int8)\n",
    "jets_OHE = get_jet_OHE(jets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing OHE for phi_centrality\n",
    "phi_centrality = X_cleaned[:, cat_indices['phi']]\n",
    "phi_centrality_OHE = get_centrality_split_OHE(phi_centrality, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new matrix\n",
    "X_OHE = np.c_[np.delete(X_cleaned, list(cat_indices.values()), axis=1), jets_OHE, phi_centrality_OHE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Scaling non-categorical feature \n",
    "so that distances are comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init vars\n",
    "tot_features = 31\n",
    "cat_features = 2\n",
    "\n",
    "X_scaled = X_OHE.copy()\n",
    "\n",
    "last_non_cat = tot_features - cat_features # All OHE features are at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale non categorical features\n",
    "scalable_features = X_scaled[:,1:last_non_cat]  # Only scale non categorical feature\n",
    "\n",
    "X_scaled[:,1:last_non_cat] = min_max_scale(scalable_features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looked at everything before this, cleaned the code a bit and made it more elegant, but it was actually already pretty good/fast (just some copy-paste errors). \n",
    "\n",
    "TODO: check KNN model func?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: delete\n",
    "\n",
    "def split_data_tmp(x,y, ratio, seed=1):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # split the data based on the given ratio: TODO    \n",
    "    p = np.random.permutation(len(y))\n",
    "    y = y[p]\n",
    "    x = x[p]\n",
    "    \n",
    "    limit = int(len(y)*ratio)\n",
    "        \n",
    "    return x[:limit],y[:limit],x[limit:],y[limit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nyneighbours=Ytrain[indexn]\\nypredclass=(yneighbours.mean()>0.5).astype(int)  #if average above 0.5 majority 1's classified as 1 otherwise classified as 0\\nypredarray[j]=ypredclass\\n\""
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "yneighbours=Ytrain[indexn]\n",
    "ypredclass=(yneighbours.mean()>0.5).astype(int)  #if average above 0.5 majority 1's classified as 1 otherwise classified as 0\n",
    "ypredarray[j]=ypredclass\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = split_data_tmp(X_scaled, Y_total, 0.8)\n",
    "\n",
    "KNN_matrix = get_KNN(X_test, X_train, Y_train, dist_manhattan, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = KNNmodel(X_test, X_train, Y_train, dist_manhattan, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_matrix.shape\n",
    "\n",
    "with open ('Data/KNN.npy', 'wb') as f:\n",
    "    np.save(f, KNN_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('Data/KNN.npy', 'rb') as f:\n",
    "    knn_test_stored = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75172"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prediction_from_knn(knn, k, y):\n",
    "    \"\"\"Given a k, y, and a list of nn, returns a prediction\"\"\"\n",
    "    \n",
    "    k_neighbors_vals = y[knn[:,:k].astype(int)]\n",
    "    k_neighbors_mean = k_neighbors_vals.mean(axis=1)\n",
    "    return probability_to_prediction(k_neighbors_mean)\n",
    "\n",
    "get_prediction_accuracy(probability_to_prediction(Y_test), get_prediction_from_knn(KNN_matrix, 4, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[147736.,  15295., 150910., ...,   9485.,  48348.,  92941.],\n",
       "       [ 32039., 151382.,  62540., ..., 151440.,  64144.,  58460.],\n",
       "       [ 24385.,  27321.,  24910., ..., 137628.,  11501., 139970.],\n",
       "       ...,\n",
       "       [181628.,  80308.,  41025., ...,  36779., 133725., 165157.],\n",
       "       [ 83453., 193027.,  63554., ...,  70371.,  41650.,  54615.],\n",
       "       [121618., 117248.,  27676., ...,  73582., 115346., 184335.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_test_storedored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indexn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-68c5fe4ebc8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myneighbours\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindexn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mypredclass\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myneighbours\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#if average above 0.5 majority 1's classified as 1 otherwise classified as 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mypredarray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mypredclass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'indexn' is not defined"
     ]
    }
   ],
   "source": [
    "def get_y:\n",
    "yneighbours=Y_train[y[0]]\n",
    "ypredclass=(yneighbours.mean()>0.5).astype(int)  #if average above 0.5 majority 1's classified as 1 otherwise classified as 0\n",
    "ypredarray[j]=ypredclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75172"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils_predictions_manipulation import*\n",
    "\n",
    "get_prediction_accuracy(Y_test, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE\n",
    "would it be possible to also (instead of splitting NAN - Non NANS and cleaning NAN's) Directly take X_total and clean NANs: remove features if more than 50% are NANs otherwise replace by median. \n",
    "\n",
    "^\n",
    "To do this, just call: 'replace_nans_with_median(X_total, 0.5)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#column indices. The headers as two extra coumn 'id' and 'predictions'\n",
    "#X matrices have only 1 extra column of ones so indices should be 1 less than in the headers \n",
    "indice_OHE=[]\n",
    "indice_OHE.append(header.index('DER_prodeta_jet_jet')-1)\n",
    "indice_OHE.append(header.index('DER_prodeta_jet_jet')-1)   # Are these two names wrong?\n",
    "indice_OHE.append(header.index('PRI_jet_num')-1)  # Shouldn't this be the first one?\n",
    "cat=[2,2,4]   # What is this used for?\n",
    "\n",
    "\n",
    "X_OHE=np.copy(X_total)  #X is the extanded \"30+1 column array\"\n",
    "\n",
    "#JetNumOHE\n",
    "colbefore=X_total[:,indice_OHE[0]] #extract column from Xtotal\n",
    "classes=[0,1,2,3]\n",
    "#initialize ohe sub-matrix for feature col\n",
    "submatrix=np.zeros((X_total.shape[0], 4))\n",
    "for i in range(4):\n",
    "    coltmp=(colbefore==classes[i]).astype(int)\n",
    "    submatrix[:,i]=coltmp\n",
    "    \n",
    "X_OHE=np.append(X_OHE, submatrix, axis=1)\n",
    "    #remove column from XOHE\n",
    "    #append new columns to XOHE\n",
    "\n",
    "#NOTE: ONLY for X_Cleaned when no NAN values for the following two features. \n",
    "#Are these two features retained with the threshold \n",
    "#LepEtaCentrality OHE\n",
    "colbefore=X_total[:,indice_OHE[1]]\n",
    "submatrix=np.zeros((X_total.shape[0], 2))\n",
    "coltmp0=(colbefore < 0.5).astype(int)\n",
    "coltmp1=(colbefore >= 0.5).astype(int)\n",
    "submatrix[:,0]=coltmp0\n",
    "submatrix[:,1]=coltmp1\n",
    "X_OHE=np.append(X_OHE, submatrix, axis=1)\n",
    "\n",
    "#LepEtaCentrality OHE\n",
    "colbefore=X_total[:,indice_OHE[2]]\n",
    "submatrix=np.zeros((X_total.shape[0], 2))\n",
    "coltmp0=(colbefore < 0).astype(int)\n",
    "coltmp1=(colbefore >= 0).astype(int)\n",
    "submatrix[:,0]=coltmp0\n",
    "submatrix[:,1]=coltmp1\n",
    "X_OHE=np.append(X_OHE, submatrix, axis=1)\n",
    "    \n",
    "\n",
    "#removing old features\n",
    "    \n",
    "X_OHE=np.delete(X_OHE, indice_OHE, axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (250000,27) into shape (27,36)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-2943d867b9ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mXmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#maximum array for the different features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msubscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmatrix\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mXmin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXmin\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mXmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mXscale\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnewindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (250000,27) into shape (27,36)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Xscale=np.copy(X_OHE)\n",
    "Original_number=31  #number of features before OHE +1 column\n",
    "number_features_OHE=3 #again if the centrality features are still part of the X data array\n",
    "newindex=Original_number-number_features_OHE\n",
    "submatrix=Xscale[:,1:newindex]  #don't scale the 1 column and the OHE variables which start at index 31-3 because we removed 3 categorical variables\n",
    "Xmin=(submatrix.min(axis=0)) #minimum array for the different features\n",
    "Xmax=(submatrix.max(axis=0)) #maximum array for the different features\n",
    "subscale=(submatrix-Xmin)/(Xmin-Xmax)\n",
    "Xscale[1:newindex]=subscale\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
